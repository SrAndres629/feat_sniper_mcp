import sys
import os
sys.path.append(os.getcwd())
import torch
from app.ml.ml_engine.doctoral_loss import DoctoralLoss

def test_doctoral_loss_math():
    print("üß™ DOCTORAL LOSS MATH AUDIT")
    print("===========================")
    
    # 1. Setup Dummy Data
    B, C = 4, 3
    logits = torch.randn(B, C, requires_grad=True)
    log_var = torch.randn(B, 1, requires_grad=True)
    p_win = torch.sigmoid(torch.randn(B, 1, requires_grad=True))
    
    targets_class = torch.tensor([0, 1, 2, 0]) # Random classes
    
    outputs = {
        "logits": logits,
        "log_var": log_var,
        "p_win": p_win
    }
    
    inputs = {
        "class": targets_class
    }
    
    # 2. Instantiate Loss
    criterion = DoctoralLoss(num_classes=C, monte_carlo_samples=100, quantile=0.5)
    
    # 3. Forward Pass
    loss = criterion(outputs, inputs)
    
    print(f"‚úÖ Forward Pass Successful. Loss: {loss.item():.4f}")
    
    # 4. Backward Pass (Check Gradients)
    loss.backward()
    
    print("‚úÖ Backward Pass Successful (Gradients propagated).")
    print(f"   Logits Grad Mean: {logits.grad.mean().item():.6f}")
    print(f"   LogVar Grad Mean: {log_var.grad.mean().item():.6f}")
    
    # 5. Stability Check
    # Verify LogSumExp usage in sub-component if possible, or trust the implementation.
    # We can invoke the stability function directly.
    print("\nüîç Stability Check (Log-Sum-Exp):")
    lse_logits = criterion.log_sum_exp_stability(logits)
    print(f"   LSE Output Mean: {lse_logits.mean().item():.4f}")
    assert not torch.isnan(lse_logits).any(), "NaN detected in LSE!"
    print("   Stability Confirmed.")

if __name__ == "__main__":
    try:
        test_doctoral_loss_math()
        print("\nüèÜ MATH SENIOR FULLSTACK APPROVES THIS MODULE.")
    except Exception as e:
        print(f"\n‚ùå AUDIT FAILED: {e}")
