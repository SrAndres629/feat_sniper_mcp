# üêç Python Pipeline - ML Backend

> **Motor de Machine Learning y Optimizaci√≥n**  
> *Bayesian Search + SQLite Persistence + Visualizaci√≥n*

---

## üéØ Prop√≥sito

El backend Python procesa los datos exportados por MT5 para:
1. **Entrenar modelos ML** para clasificaci√≥n de estados
2. **Optimizar umbrales** con b√∫squeda bayesiana (Optuna)
3. **Persistir hist√≥rico** en SQLite
4. **Generar dashboards** HTML interactivos

---

## üóÇÔ∏è Estructura de Archivos

```
Python/
‚îú‚îÄ‚îÄ run_pipeline.py          # üéØ Orquestador principal
‚îú‚îÄ‚îÄ db_engine.py             # üíæ Motor SQLite
‚îú‚îÄ‚îÄ ml_engine.py             # üß† Clasificador FSM
‚îú‚îÄ‚îÄ optuna_optimizer.py      # üî¨ Optimizaci√≥n Bayesiana
‚îú‚îÄ‚îÄ stats_engine.py          # üìä Motor estad√≠stico
‚îú‚îÄ‚îÄ viz_engine.py            # üìà Generador de dashboards
‚îú‚îÄ‚îÄ validator.py             # ‚úÖ Validaci√≥n de configuraci√≥n
‚îú‚îÄ‚îÄ brute_force.py           # üîß Optimizaci√≥n bruta (legacy)
‚îú‚îÄ‚îÄ institutional_bridge.py  # üåâ Bridge HTTP con MT5
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt         # üì¶ Dependencias
‚îú‚îÄ‚îÄ bridge_config.json       # ‚öôÔ∏è Configuraci√≥n del bridge
‚îú‚îÄ‚îÄ start_bridge.bat         # üöÄ Script de inicio (Windows)
‚îÇ
‚îú‚îÄ‚îÄ unified_model.db         # üíæ Base de datos SQLite
‚îú‚îÄ‚îÄ fsm_model.joblib         # üß† Modelo entrenado
‚îú‚îÄ‚îÄ optuna_calibration.json  # üìê Umbrales optimizados
‚îú‚îÄ‚îÄ ml_thresholds.json       # üìê Umbrales ML
‚îú‚îÄ‚îÄ validation_report.json   # üìã Reporte de validaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ mock_data.csv            # üß™ Datos de prueba
‚îú‚îÄ‚îÄ dashboard.html           # üìä Dashboard generado
‚îî‚îÄ‚îÄ pipeline.log             # üìù Log de ejecuci√≥n
```

---

## üöÄ Quick Start

### 1. Instalar Dependencias
```bash
cd Python/
pip install -r requirements.txt
```

### 2. Ejecutar Pipeline Completo
```bash
python run_pipeline.py --input mock_data.csv --symbol EURUSD --tf H1
```

### 3. Solo Optimizaci√≥n
```bash
python optuna_optimizer.py
```

---

## üì¶ M√≥dulos

### 1. run_pipeline.py - Orquestador Principal

```python
"""
Ejecuta el pipeline completo:
1. Ingest Data (CSV -> DB)
2. Train/Update Models (ML Engine)
3. Optimize Thresholds (Optuna)
4. Visualize Results (Viz Engine)
"""

def main():
    # 1. Load and validate CSV
    df = load_and_validate_csv(args.input)
    
    # 2. Ingest to database
    ingest_to_db(db, df, args.symbol, args.timeframe)
    
    # 3. Run ML pipeline
    classifier = run_ml_pipeline(df, output_dir)
    
    # 4. Run optimization
    opt_results = run_optimization_pipeline(df, output_dir, symbol, tf)
    
    # 5. Generate visualization
    run_viz_pipeline(df, classifier, opt_results, output_dir, symbol, tf)
```

**Argumentos CLI:**
| Argumento | Default | Descripci√≥n |
|-----------|---------|-------------|
| `--input` | `mock_data.csv` | Archivo CSV de entrada |
| `--symbol` | `EURUSD` | S√≠mbolo del instrumento |
| `--tf` | `H1` | Timeframe |
| `--output` | `.` | Directorio de salida |

---

### 2. db_engine.py - Motor SQLite

```python
class UnifiedModelDB:
    """
    SQLite database for Unified Model state history and calibration.
    
    Tables:
    - state_history: All state observations
    - transitions: State transition events
    - calibrations: Threshold configurations
    """
```

**Tablas del Schema:**

#### state_history
| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| `id` | INTEGER | Primary key |
| `timestamp` | DATETIME | Momento de observaci√≥n |
| `symbol` | TEXT | S√≠mbolo (EURUSD, etc.) |
| `timeframe` | TEXT | Timeframe (H1, M5, etc.) |
| `state` | TEXT | Estado FSM detectado |
| `confidence` | REAL | Confianza (0-100) |
| `effort` | REAL | M√©trica de esfuerzo |
| `result` | REAL | M√©trica de resultado |
| `compression` | REAL | Compresi√≥n EMA |
| `slope` | REAL | Pendiente normalizada |
| `speed` | REAL | Velocidad de precio |
| `feat_score` | REAL | Score FEAT consolidado |

#### transitions
| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| `from_state` | TEXT | Estado anterior |
| `to_state` | TEXT | Estado nuevo |
| `confidence` | REAL | Confianza de transici√≥n |
| `reason` | TEXT | Raz√≥n del cambio |

#### calibrations
| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| `thresholds_json` | TEXT | Umbrales en JSON |
| `score` | REAL | Score de optimizaci√≥n |
| `method` | TEXT | M√©todo usado (optuna, brute_force) |
| `is_active` | BOOLEAN | ¬øEs la calibraci√≥n activa? |

**API Principal:**
```python
db = UnifiedModelDB("unified_model.db")

# Logging
db.log_state(symbol, timeframe, state, confidence, metrics)
db.log_transition(symbol, tf, from_state, to_state, confidence, reason)

# Queries
history = db.get_state_history(symbol, tf, start_time, end_time)
distribution = db.get_state_distribution(symbol, tf, days=30)
matrix = db.get_transition_matrix(symbol, tf, days=30)

# Calibration
db.save_calibration(symbol, tf, thresholds, score, method)
active = db.get_active_calibration(symbol, tf)

# Export
db.export_to_csv("state_history", "history.csv", symbol, tf)
```

---

### 3. optuna_optimizer.py - Optimizaci√≥n Bayesiana

```python
class OptunaOptimizer:
    """
    Bayesian optimization for FSM thresholds using Optuna.
    
    Advantages over brute force:
    1. Intelligent sampling with TPE (Tree-structured Parzen Estimator)
    2. Early pruning of unpromising trials
    3. ~30-100x faster than grid search
    """
```

**Par√°metros Optimizados:**
```python
# Effort thresholds
effort_p20 = trial.suggest_float("effort_p20", 0.1, 0.5)
effort_p80 = trial.suggest_float("effort_p80", 0.8, 2.0)

# Result thresholds
result_p20 = trial.suggest_float("result_p20", 0.1, 0.5)
result_p80 = trial.suggest_float("result_p80", 0.5, 1.5)

# Layer thresholds
layer_sep = trial.suggest_float("layer_sep", 0.5, 3.0)
bias_slope = trial.suggest_float("bias_slope", 0.1, 0.5)
```

**Configuraci√≥n:**
```python
@dataclass
class OptimizationConfig:
    n_trials: int = 100           # N√∫mero de trials
    timeout: Optional[int] = None # Timeout en segundos
    n_startup_trials: int = 10    # Trials aleatorios iniciales
    n_warmup_steps: int = 5       # Steps de warmup
    seed: int = 42                # Seed para reproducibilidad
    show_progress: bool = True    # Mostrar barra de progreso
```

**Uso:**
```python
optimizer = OptunaOptimizer()
optimizer.set_data(effort, result, compression, slope, speed)
best_thresholds = optimizer.optimize()
optimizer.export_calibration("optuna_calibration.json", "EURUSD", "H1")
```

**Output (optuna_calibration.json):**
```json
{
  "symbol": "EURUSD",
  "timeframe": "H1",
  "optimization_method": "optuna",
  "trials": 100,
  "best_score": 0.847,
  "thresholds": {
    "effort_p20": 0.32,
    "effort_p80": 1.45,
    "result_p20": 0.28,
    "result_p80": 0.92,
    "layer_sep": 2.1,
    "bias_slope": 0.25
  }
}
```

---

### 4. ml_engine.py - Clasificador FSM

```python
class FSMClassifier:
    """
    Machine Learning classifier for market states.
    Uses Random Forest with feature engineering.
    """
    
    def train(self, X, y):
        # Feature engineering
        X_eng = self._engineer_features(X)
        
        # Train classifier
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        self.model.fit(X_eng, y)
    
    def predict(self, X):
        X_eng = self._engineer_features(X)
        return self.model.predict(X_eng)
    
    def save(self, path):
        joblib.dump(self.model, path)
    
    def load(self, path):
        self.model = joblib.load(path)
```

**Features de Entrada:**
| Feature | Descripci√≥n |
|---------|-------------|
| `effort` | Volumen normalizado |
| `result` | Movimiento de precio / ATR |
| `compression` | Compresi√≥n de capa Micro |
| `slope` | Pendiente de capa Operational |
| `speed` | Gap Micro-Oper / ATR |
| `rsi` | Valor RSI |
| `macd_hist` | Histograma MACD |

**Output:**
- `fsm_model.joblib` - Modelo serializado

---

### 5. viz_engine.py - Generador de Dashboards

```python
class VizEngine:
    """
    Generates comprehensive HTML dashboards with:
    - State distribution charts
    - Transition heatmaps
    - Performance metrics
    - Calibration history
    """
```

**Gr√°ficos Generados:**
1. **State Distribution** - Pie chart de estados
2. **Transition Heatmap** - Matriz de transiciones
3. **Time Series** - Estados en el tiempo
4. **Effort vs Result Scatter** - Distribuci√≥n de m√©tricas
5. **Calibration History** - Evoluci√≥n de scores

**Output:**
- `dashboard.html` - Dashboard interactivo (~5MB)

---

## üìä Flujo de Datos

```mermaid
sequenceDiagram
    participant MT5 as MetaTrader 5
    participant CSV as CSV File
    participant Pipe as run_pipeline.py
    participant DB as SQLite
    participant ML as ml_engine.py
    participant Opt as optuna_optimizer.py
    participant Viz as viz_engine.py
    
    MT5->>CSV: Export via CInterop
    CSV->>Pipe: Load data
    Pipe->>DB: Ingest records
    DB->>ML: Query training data
    ML->>ML: Train classifier
    ML->>Pipe: Return model
    DB->>Opt: Query metrics
    Opt->>Opt: Bayesian search
    Opt->>Pipe: Return best thresholds
    Pipe->>Viz: Generate dashboard
    Viz->>Viz: Create HTML
    Opt->>MT5: Export calibration JSON
```

---

## ‚öôÔ∏è Configuraci√≥n

### requirements.txt
```
pandas>=1.5.0
numpy>=1.23.0
scikit-learn>=1.1.0
optuna>=3.0.0
plotly>=5.0.0
joblib>=1.2.0
```

### bridge_config.json
```json
{
  "host": "127.0.0.1",
  "port": 8888,
  "db_path": "unified_model.db",
  "export_path": "../",
  "log_level": "INFO"
}
```

---

## üß™ Testing

```bash
# Run with mock data
python run_pipeline.py --input mock_data.csv

# Check pipeline.log for execution details
tail -f pipeline.log

# Validate output
python validator.py --config optuna_calibration.json
```

---

## ‚ö†Ô∏è Notas Importantes

> [!WARNING]
> El archivo `dashboard.html` puede pesar ~5MB debido a los gr√°ficos embebidos.
> Para dashboards m√°s livianos, usar `viz_engine.py` con `embed_data=False`.

> [!TIP]
> Para calibraci√≥n r√°pida, usa `run_quick_optimization()` con `n_trials=50`.

> [!NOTE]
> Los modelos se guardan en formato `joblib` para compatibilidad con scikit-learn.

---

*M√≥dulo: Python Pipeline*  
*Versi√≥n: 2.0*
